{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from tqdm import tqdm \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration aihub-news30k-7dc905421859817c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/aihub-news30k to /opt/ml/.cache/huggingface/datasets/csv/aihub-news30k-7dc905421859817c/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390ff384652d41bcb4682299488cb8a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52fa6083a8c46bb9bf8f66edb55f164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d0f4a21f23449f86c80f70d0192d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9680c582c3b416aba461d1959980176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /opt/ml/.cache/huggingface/datasets/csv/aihub-news30k-7dc905421859817c/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d5eaffdaa946d094493e86e993d114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', '0'],\n",
       "        num_rows: 27303\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "news_train_dataset = datasets.load_dataset('nlpHakdang/aihub-news30k',  data_files = \"train_news_text.csv\", use_auth_token='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')\n",
    "news_train_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>여수광양항만공사(사장 박희석)는 14일부터 20일까지 광양항 배후 투자 유치를 위해...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>포스코 광양제철소(소장 임학동)가 자동차 강판 생산공장인 제3냉연공장을 최신 설비로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>여수광양항만공사(사장 밤 희석, 이하 공사)는 2018년도 승진 전 보 인사를 단행...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>광양시는 경쟁력을 갖춘 풍요로운 농어촌 건설을 위해 원예작물 신기술 보급사업을 통한...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>포스코 광양제철소(소장 임학동)가 ‘사랑 나눔 헌혈 행사’를 실시하며 생명 나눔을 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                  0\n",
       "0           0  여수광양항만공사(사장 박희석)는 14일부터 20일까지 광양항 배후 투자 유치를 위해...\n",
       "1           1  포스코 광양제철소(소장 임학동)가 자동차 강판 생산공장인 제3냉연공장을 최신 설비로...\n",
       "2           2  여수광양항만공사(사장 밤 희석, 이하 공사)는 2018년도 승진 전 보 인사를 단행...\n",
       "3           3  광양시는 경쟁력을 갖춘 풍요로운 농어촌 건설을 위해 원예작물 신기술 보급사업을 통한...\n",
       "4           4  포스코 광양제철소(소장 임학동)가 ‘사랑 나눔 헌혈 행사’를 실시하며 생명 나눔을 ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_train_df = pd.DataFrame( news_train_dataset['train'] )\n",
    "news_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>여수광양항만공사(사장 박희석)는 14일부터 20일까지 광양항 배후 투자 유치를 위해...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>포스코 광양제철소(소장 임학동)가 자동차 강판 생산공장인 제3냉연공장을 최신 설비로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>여수광양항만공사(사장 밤 희석, 이하 공사)는 2018년도 승진 전 보 인사를 단행...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>광양시는 경쟁력을 갖춘 풍요로운 농어촌 건설을 위해 원예작물 신기술 보급사업을 통한...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>포스코 광양제철소(소장 임학동)가 ‘사랑 나눔 헌혈 행사’를 실시하며 생명 나눔을 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  여수광양항만공사(사장 박희석)는 14일부터 20일까지 광양항 배후 투자 유치를 위해...\n",
       "1  포스코 광양제철소(소장 임학동)가 자동차 강판 생산공장인 제3냉연공장을 최신 설비로...\n",
       "2  여수광양항만공사(사장 밤 희석, 이하 공사)는 2018년도 승진 전 보 인사를 단행...\n",
       "3  광양시는 경쟁력을 갖춘 풍요로운 농어촌 건설을 위해 원예작물 신기술 보급사업을 통한...\n",
       "4  포스코 광양제철소(소장 임학동)가 ‘사랑 나눔 헌혈 행사’를 실시하며 생명 나눔을 ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_train_df = news_train_df.drop('Unnamed: 0', axis = 1)\n",
    "news_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = news_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"news_dict_nouns.pickle\",\"wb\") as f:\n",
    "#     pickle.dump(nouns, f)\n",
    "with open(\"news_dict_nouns.pickle\",\"rb\") as f :\n",
    "    nouns = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_list = []\n",
    "# for key, val in nouns.items():\n",
    "#     len_list.append((key, len(val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del(nouns['전방'])\n",
    "# del(pre_dict['전방'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del(pre_dict['대상'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sorted(len_list, key = lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_dict = {}\n",
    "for key, vals in nouns.items():\n",
    "    pre_list = []\n",
    "    if len(vals) == 0:\n",
    "        continue\n",
    "    for val in vals:\n",
    "        pre_list.append(val.replace(key,\"[MASK]\"))\n",
    "    pre_dict[key] = pre_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = [\"corp\",\"plain\",\"masked\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for key in nouns.keys():\n",
    "    for idx in range(len(nouns[key])):\n",
    "        data_list.append([key, nouns[key][idx],pre_dict[key][idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145240"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_list, columns=col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"dataset.pickle\",\"wb\") as f:\n",
    "#     pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, _, _= train_test_split(\n",
    "    df,df['corp'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid, test, _, _= train_test_split(\n",
    "    test,test['corp'], test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_corp = {idx:list(nouns.keys())[idx] for idx in range(len(list(nouns.keys())))}\n",
    "corp_to_label = {val:idx for idx, val in label_to_corp.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13678"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_length = [len(txt) for txt in df['plain'].values]\n",
    "max(news_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration beneficiary-15e09db052e9f529\n",
      "Reusing dataset csv (/opt/ml/.cache/huggingface/datasets/csv/beneficiary-15e09db052e9f529/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68bcd2c72f0546c699f7dceb6b14c7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "dartdataset = datasets.load_dataset('nlpHakdang/beneficiary',  data_files = \"dart_v3_01.csv\", use_auth_token='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')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocessing_only_kr(s): \n",
    "        hangul = re.compile('[^ ㄱ-ㅣ가-힣+]')\n",
    "        result = hangul.sub('', s)\n",
    "        return ' '.join(result.split())\n",
    "\n",
    "def preprocessing(s): \n",
    "        hangul = re.compile('[^ a-zA-Z0-9ㄱ-ㅣ가-힣+]')\n",
    "        result = hangul.sub('', s)\n",
    "        return ' '.join(result.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2410"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess = [preprocessing(txt) for txt in dartdataset['train']['사업의 개요']]\n",
    "dartdata = [dartdataset['train']['기업 이름'],preprocess]\n",
    "dartdf = pd.DataFrame (dartdata).transpose()\n",
    "dartdf.columns = ['corp', 'txt']\n",
    "len(dartdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stride Code\n",
    "#### DART\n",
    "- 데이터의 형태 colum = ['corp', 'txt']\n",
    "    - corp : 기업이름, txt : 사업의 개요\n",
    "- corp_to_label : 회사이름을 정수로 바꾸는 딕셔너리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dart_split(df : pd.DataFrame) -> pd.DataFrame : \n",
    "    data_list2 = []\n",
    "    for idx in tqdm(range(len(df))):\n",
    "        stride = []\n",
    "        txt = df.iloc[idx]['txt']\n",
    "        if len(txt) < 512:\n",
    "            # if df.iloc[idx]['corp'] not in corp_to_label:\n",
    "                # continue\n",
    "            data_list2.append([df.iloc[idx]['corp'],df.iloc[idx]['txt']])\n",
    "        else:\n",
    "            for pointer in range(len(txt)//300):\n",
    "                if pointer == len(txt)//300-1:\n",
    "                    split_txt = txt[-400:]\n",
    "                elif pointer != 0:\n",
    "                    split_txt = txt[(pointer*300)-100:((pointer+1)*300)+100]\n",
    "                elif pointer == 0:\n",
    "                    split_txt = txt[:400]\n",
    "                # elif df.iloc[idx]['corp'] not in corp_to_label:\n",
    "                #     continue\n",
    "                data_list2.append([df.iloc[idx]['corp'],split_txt])\n",
    "    return pd.DataFrame(data_list2,columns=['corp', 'txt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### News\n",
    "- 데이터의 형태 colum = ['corp', 'plain', 'maked']\n",
    "    - corp : 기업이름, plain : 원본텍스트, masked:마스크된 텍스트\n",
    "- corp_to_label : 회사이름을 정수로 바꾸는 딕셔너리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_split(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    data_list2 = []\n",
    "    for idx in tqdm(range(len(df))):\n",
    "        stride = []\n",
    "        txt = df.iloc[idx]['0']\n",
    "        if txt == None:\n",
    "            continue\n",
    "        if len(txt) < 512:\n",
    "            data_list2.append([df.iloc[idx]['0']])\n",
    "        else:\n",
    "            for pointer in range(len(txt)//300):\n",
    "                if pointer == len(txt)//300-1:\n",
    "                    split_txt = txt[-400:]\n",
    "                if pointer != 0:\n",
    "                    split_txt = txt[(pointer*300)-100:((pointer+1)*300)+100]\n",
    "                if pointer == 0:\n",
    "                    split_txt = txt[:400]\n",
    "                data_list2.append([split_txt])\n",
    "    return pd.DataFrame(data_list2,columns=['divided'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27303/27303 [00:02<00:00, 11813.85it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = bert_split(train)\n",
    "# valid_df = bert_split(valid)\n",
    "# test_df = bert_split(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>divided</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>여수광양항만공사(사장 박희석)는 14일부터 20일까지 광양항 배후 투자 유치를 위해...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>은 먼저 광양항 서측 배후 푸드존 투자유치를 위해 중국 윈난성 소재 커피 원재료 공...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>포스코 광양제철소(소장 임학동)가 자동차 강판 생산공장인 제3냉연공장을 최신 설비로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>판 중 높은 품질기술력을 요구하는 자동차 외판 생산 증대에 초점을 두고 진행됐다. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>여수광양항만공사(사장 밤 희석, 이하 공사)는 2018년도 승진 전 보 인사를 단행...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             divided\n",
       "0  여수광양항만공사(사장 박희석)는 14일부터 20일까지 광양항 배후 투자 유치를 위해...\n",
       "1  은 먼저 광양항 서측 배후 푸드존 투자유치를 위해 중국 윈난성 소재 커피 원재료 공...\n",
       "2  포스코 광양제철소(소장 임학동)가 자동차 강판 생산공장인 제3냉연공장을 최신 설비로...\n",
       "3  판 중 높은 품질기술력을 요구하는 자동차 외판 생산 증대에 초점을 두고 진행됐다. ...\n",
       "4  여수광양항만공사(사장 밤 희석, 이하 공사)는 2018년도 승진 전 보 인사를 단행..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corp</th>\n",
       "      <th>plain</th>\n",
       "      <th>masked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131090</th>\n",
       "      <td>한화</td>\n",
       "      <td>금융권이 주 52시간 근무제의 법적 시행을 일주일 앞두고 마지막 점검 중이다은행권은...</td>\n",
       "      <td>금융권이 주 52시간 근무제의 법적 시행을 일주일 앞두고 마지막 점검 중이다은행권은...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111221</th>\n",
       "      <td>태양</td>\n",
       "      <td>한국화학연구원이하 화학연이 차세대 태양전지로 주목받는 페로브스카이트 태양전지 최고 ...</td>\n",
       "      <td>한국화학연구원이하 화학연이 차세대 [MASK]전지로 주목받는 페로브스카이트 [MAS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40789</th>\n",
       "      <td>현대건설</td>\n",
       "      <td>서울 용산 한남3구역 재개발 사업이 국토교통부 서울시의 모호한 방침 때문에 혼란에 ...</td>\n",
       "      <td>서울 용산 한남3구역 재개발 사업이 국토교통부 서울시의 모호한 방침 때문에 혼란에 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97947</th>\n",
       "      <td>대상</td>\n",
       "      <td>에이스침대가 봄을 맞아 다양한 브랜드 제품을 한 자리에서 만날 수 있는 에이스 브랜...</td>\n",
       "      <td>에이스침대가 봄을 맞아 다양한 브랜드 제품을 한 자리에서 만날 수 있는 에이스 브랜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97517</th>\n",
       "      <td>대상</td>\n",
       "      <td>이데일리 김지섭 기자 JW그룹 신입사원들이 새해를 맞아 뜻 깊은 봉사활동을 진행했다...</td>\n",
       "      <td>이데일리 김지섭 기자 JW그룹 신입사원들이 새해를 맞아 뜻 깊은 봉사활동을 진행했다...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        corp                                              plain  \\\n",
       "131090    한화  금융권이 주 52시간 근무제의 법적 시행을 일주일 앞두고 마지막 점검 중이다은행권은...   \n",
       "111221    태양  한국화학연구원이하 화학연이 차세대 태양전지로 주목받는 페로브스카이트 태양전지 최고 ...   \n",
       "40789   현대건설  서울 용산 한남3구역 재개발 사업이 국토교통부 서울시의 모호한 방침 때문에 혼란에 ...   \n",
       "97947     대상  에이스침대가 봄을 맞아 다양한 브랜드 제품을 한 자리에서 만날 수 있는 에이스 브랜...   \n",
       "97517     대상  이데일리 김지섭 기자 JW그룹 신입사원들이 새해를 맞아 뜻 깊은 봉사활동을 진행했다...   \n",
       "\n",
       "                                                   masked  \n",
       "131090  금융권이 주 52시간 근무제의 법적 시행을 일주일 앞두고 마지막 점검 중이다은행권은...  \n",
       "111221  한국화학연구원이하 화학연이 차세대 [MASK]전지로 주목받는 페로브스카이트 [MAS...  \n",
       "40789   서울 용산 한남3구역 재개발 사업이 국토교통부 서울시의 모호한 방침 때문에 혼란에 ...  \n",
       "97947   에이스침대가 봄을 맞아 다양한 브랜드 제품을 한 자리에서 만날 수 있는 에이스 브랜...  \n",
       "97517   이데일리 김지섭 기자 JW그룹 신입사원들이 새해를 맞아 뜻 깊은 봉사활동을 진행했다...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2410/2410 [00:01<00:00, 1765.16it/s]\n"
     ]
    }
   ],
   "source": [
    "dartdf.head()\n",
    "split_dart_df = dart_split(dartdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corp</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>엑세스바이오</td>\n",
       "      <td>당사는 체외진단 기술을 토대로 면역화학진단 바이오센서 분자진단 기술을 기반으로 진단...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>엑세스바이오</td>\n",
       "      <td>어 의약품 제조기준에 규제를 받고 있습니다 체외진단 시장은 인구 고령화 및 감염성 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>엑세스바이오</td>\n",
       "      <td>019년 신개발 의료기기 전망분석 보고서 에 따르면 체외진단기기 세계시장은 2015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>엑세스바이오</td>\n",
       "      <td>FDA로부터 긴급사용승인 Emergency Use Authorization 을 획...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>지오엠씨</td>\n",
       "      <td>가 영업의 현황 당사는 30년간 지속적으로 진행해 오고 있는 엠씨스퀘어 사업 부문과...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     corp                                                txt\n",
       "0  엑세스바이오  당사는 체외진단 기술을 토대로 면역화학진단 바이오센서 분자진단 기술을 기반으로 진단...\n",
       "1  엑세스바이오  어 의약품 제조기준에 규제를 받고 있습니다 체외진단 시장은 인구 고령화 및 감염성 ...\n",
       "2  엑세스바이오  019년 신개발 의료기기 전망분석 보고서 에 따르면 체외진단기기 세계시장은 2015...\n",
       "3  엑세스바이오   FDA로부터 긴급사용승인 Emergency Use Authorization 을 획...\n",
       "4    지오엠씨  가 영업의 현황 당사는 30년간 지속적으로 진행해 오고 있는 엠씨스퀘어 사업 부문과..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train), len(test), len(train_df), len(test_df), len(dartdf), len(split_dart_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.iloc[0:3]['masked'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.iloc[0:3]['masked'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.iloc[0:3]['masked'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dart = split_dart_df.rename_axis('id').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_to_corp = {}\n",
    "# for idx in range(len(split_dart)):\n",
    "#     id_to_corp[split_dart.iloc[idx]['id']] = split_dart.iloc[idx]['corp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BertModel, BertPreTrainedModel\n",
    ")\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dart_tok = tokenizer( list(split_dart_df['txt']) ,padding = \"max_length\", return_tensors = \"pt\", truncation = True) \n",
    "train_tok = tokenizer( list(train_df['divided']) ,padding = \"max_length\", return_tensors = \"pt\", truncation = True)\n",
    "# valid_tok = tokenizer( list(valid_df['masked']) ,padding = \"max_length\", return_tensors = \"pt\", truncation = True)\n",
    "# test_tok = tokenizer(list(test_df['masked']),padding = \"max_length\", return_tensors = \"pt\", truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_corp_code = torch.tensor(train_df['corp'])\n",
    "# valid_corp_code = torch.tensor(valid_df['corp'])\n",
    "# test_corp_code = torch.tensor(test_df['corp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dart_tok['input_ids'].shape#, train_tok['input_ids'].shape, train_corp_code.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dart_tok.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_set = TensorDataset(\n",
    "    train_tok['input_ids'], train_tok['token_type_ids'], train_tok['attention_mask'])\n",
    "    # train_corp_code)\n",
    "dart_set = TensorDataset(\n",
    "    dart_tok['input_ids'], dart_tok['token_type_ids'], dart_tok['attention_mask'])\n",
    "# valid_set = TensorDataset(\n",
    "#     valid_tok['input_ids'], valid_tok['token_type_ids'], valid_tok['attention_mask'], \\\n",
    "#     valid_corp_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "newsloader = DataLoader(news_set, batch_size=BATCH_SIZE, shuffle = False)\n",
    "BATCH_SIZE = 16\n",
    "dartloader = DataLoader(dart_set, batch_size=BATCH_SIZE, shuffle = False)\n",
    "\n",
    "# val_dataloader = DataLoader(valid_set, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(BertEncoder, self).__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self,\n",
    "            input_ids, \n",
    "            attention_mask=None,\n",
    "            token_type_ids=None\n",
    "        ): \n",
    "  \n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        pooled_output = outputs[1]\n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "news_encoder = BertEncoder.from_pretrained(\"klue/bert-base\").to(device)\n",
    "dart_encoder = BertEncoder.from_pretrained(\"klue/bert-base\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[300.42413330078125,\n",
       " 297.0402526855469,\n",
       " 297.3707580566406,\n",
       " 298.8297424316406,\n",
       " 297.8077697753906]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq \n",
    "first_b = next(iter(newsloader))\n",
    "top5 = []\n",
    "dart_emb_list = []\n",
    "with torch.no_grad():\n",
    "    news_emb = news_encoder( first_b[0].to(device), first_b[1].to(device), first_b[2].to(device) ) # (1, emb)\n",
    "\n",
    "    for i, b in enumerate(dartloader):\n",
    "        \n",
    "        dart_emb = news_encoder( b[0].to(device), b[1].to(device), b[2].to(device) ) # (B, emb)\n",
    "\n",
    "        sim_score_mat = torch.matmul(dart_emb, news_emb.T ) # (B, 1)\n",
    "        sim_score_vec = sim_score_mat.view(-1)\n",
    "        max_idx = torch.argmax(sim_score_vec)\n",
    "        \n",
    "        top5.extend(sim_score_vec.tolist())\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "            # print(sim_score_vec.shape)\n",
    "        del dart_emb\n",
    "        torch.cuda.empty_cache()\n",
    "    del news_emb\n",
    "\n",
    "top5[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20684,\n",
       " [300.42413330078125,\n",
       "  297.0402526855469,\n",
       "  297.3707580566406,\n",
       "  298.8297424316406,\n",
       "  297.8077697753906,\n",
       "  297.5516662597656,\n",
       "  294.0634765625,\n",
       "  294.519775390625,\n",
       "  296.3714904785156,\n",
       "  298.7331237792969])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top5), top5[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20688"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dartloader) * BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_tuple = []\n",
    "for i, t in enumerate(top5):\n",
    "    top5_tuple.append( (i, t) )\n",
    "\n",
    "\n",
    "top5_tuple = list(sorted(top5_tuple, key = lambda x:x[1]))\n",
    "top_idx = top5_tuple[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'여수광양항만공사(사장 박희석)는 14일부터 20일까지 광양항 배후 투자 유치를 위해 CEO가 직접 참여하는 투자유치 활동을 중국 중남부 지역에서 펼친다. 자유 구역청과 합동으로 진행되는 번 투자유치 활동은 방희선 사장이 직접 중국 현지의 투자의 향 기업을 방문해 광양항 배후 단지의 장점 등을 소개하고 투자협약(MOU)을 체결하는 방식으로 진행된다. 방 사장은 먼저 광양항 서측 배후 푸드존 투자유치를 위해 중국 윈난성 소재 커피 원재료 공급업체인 운남허메이격치(주)를 방문해 광양항 배후 투자협약을 체결할 예정이다. 투자유치 활동은 지난해 9월 경제청과 공사가 합동으로 중국 지역 투자유치 활동을 통해 투자의 향 기업을 선정했던 후속 조치로, 번 방문을 통해 광양항 배후 단지에 실질적인 투자가 이뤄질 수 있도록 '"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[0]['divided']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 3 성장했으며 2017 2022년까지 연평균 7 6 성장하면서 6902억 달러에 달할 것으로 전망되었습니다 세계 IT 서비스 시장 규모는 2018년 6942억 달러로 전년 대비 3 2 성장하였으며 2017 2022년까지 연평균 3 8 성장하면서 7835억 달러에 달할 것으로 전망되었습니다 세계 게임 SW 시장 규모는 2018년 1379억 달러로 전년 대비 13 3 성장하였으며 2017 2021년까지 연평균 10 3 성장하면서 1801억 달러에 달할 것으로 전망되었습니다 나 국내 시장 전망 글로벌 시장과 마찬가지로 국내 소프트웨어 시장도 견조한 성장세를 유지하고 있으며 지속적으로 성장세를 이어갈 것으로 전망됩니다 2018 국내 SW수출 연평균 성장률은 게임SW 부문이 24 7 로 전체 연평균 성장률 11 2 를 크게 웃돌았으며 IT서비스는 3 8 패키지 SW는 7 1 성장하며 전체 성장률보다 낮은 성장을 보였습니다 2018년 국내 SW시장은 전년 대비 4 2 성장하여 24조 원 시\n",
      "당사의 사업은 마트글라스 투명전광유리 판매 사업과 비메모리반도체의 일종인 CMOS이미지센서의 개발과 판매 사업입니다\n",
      "가 사업부문별 영업내용 나 사업부문별 요재무정보\n",
      "섬유제품 제조판매 및 임대사업\n",
      "골판지 상자 매출액비율 100 의 매출구조를 갖춘 골판지용지 일관생산 전문업체로서 별도의 사업부문은 구분하지 않습니다 조직도\n"
     ]
    }
   ],
   "source": [
    "for t in top5_tuple[:5]:\n",
    "    print( split_dart_df.iloc[t[0]]['txt'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "news_optimizer = optim.SGD(news_encoder.parameters(), lr=0.01, momentum=0.9)\n",
    "dart_optimizer = optim.SGD(dart_encoder.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "epochs = 3\n",
    "for e in range( epochs ):\n",
    "    e_loss = 0\n",
    "    for batch in tq.tqdm( dataloader ):\n",
    "        news_data = {\n",
    "            'input_ids' : batch[0].to(device).to(torch.int64), # ( B, seq_len )\n",
    "            'token_type_ids' : batch[1].to(device).to(torch.int64),\n",
    "            'attention_mask' : batch[2].to(device).to(torch.int64),\n",
    "        }\n",
    "        \n",
    "        dart_data = {\n",
    "            'input_ids' : batch[3].to(device).to(torch.int64), # ( B, seq_len )\n",
    "            'token_type_ids' : batch[4].to(device).to(torch.int64),\n",
    "            'attention_mask' : batch[5].to(device).to(torch.int64),\n",
    "        }\n",
    "\n",
    "        corp_table = batch[6]\n",
    "\n",
    "\n",
    "        corp_code = corp_table.tolist()\n",
    "        dic = {}\n",
    "\n",
    "\n",
    "        batch_size = batch[0].shape[0]\n",
    "        del batch\n",
    "        \n",
    "        news_encoder.train()\n",
    "        news_encoder.zero_grad()\n",
    "        news_emb = news_encoder(**news_data) # (B, hidden_dim)\n",
    "        dart_encoder.train()\n",
    "        dart_encoder.zero_grad()\n",
    "        dart_emb = dart_encoder(**dart_data) # (B, hidden_dim)\n",
    "        sim_score = torch.matmul( news_emb, dart_emb.T ) # (B , B)\n",
    "        \n",
    "        target = torch.arange(start=0, end = batch_size).to(device).to(torch.int64)\n",
    "    \n",
    "        CE_loss = CrossEntropyLoss()\n",
    "        loss = CE_loss(sim_score, target)\n",
    "        e_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        dart_optimizer.step()\n",
    "        news_optimizer.step()\n",
    "\n",
    "        del dart_emb\n",
    "        del news_emb\n",
    "        torch.cuda.empty_cache()\n",
    "    print(e_loss / len(dataloader))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "lightweight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
