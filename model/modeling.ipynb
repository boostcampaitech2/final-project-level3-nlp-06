{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"news_dict.pickle\",\"rb\") as f :\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list = []\n",
    "for key, val in data.items():\n",
    "    len_list.append((key, len(val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = sorted(len_list, key = lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('대상', 65640),\n",
       " ('레이', 23658),\n",
       " ('SK', 7550),\n",
       " ('동양', 7110),\n",
       " ('LG', 6228),\n",
       " ('신한', 6142),\n",
       " ('디오', 6037),\n",
       " ('성원', 5473),\n",
       " ('동아', 5022),\n",
       " ('남성', 4812)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2592/2592 [12:19<00:00,  3.50it/s] \n"
     ]
    }
   ],
   "source": [
    "nouns = {}\n",
    "for key, vals in tqdm(data.items()):\n",
    "    tot = []\n",
    "    for txt in vals:\n",
    "        txt_list = tokenizer.nouns(txt)\n",
    "        if key in txt_list :\n",
    "            tot.append(txt)\n",
    "    nouns[key] = tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"news_dict_nouns.pickle\",\"wb\") as f:\n",
    "    pickle.dump(nouns, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list = []\n",
    "for key, val in nouns.items():\n",
    "    len_list.append((key, len(val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(nouns['전방'])\n",
    "del(pre_dict['전방'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(pre_dict['대상'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sorted(len_list, key = lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_dict = {}\n",
    "for key, vals in nouns.items():\n",
    "    pre_list = []\n",
    "    if len(vals) == 0:\n",
    "        continue\n",
    "    for val in vals:\n",
    "        pre_list.append(val.replace(key,\"[MASK]\"))\n",
    "    pre_dict[key] = pre_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = [\"corp\",\"plain\",\"masked\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for key in nouns.keys():\n",
    "    for idx in range(len(nouns[key])):\n",
    "        data_list.append([key, nouns[key][idx],pre_dict[key][idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74396"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_list, columns=col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset.pickle\",\"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, _, _= train_test_split(\n",
    "    df,df['corp'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid, test, _, _= train_test_split(\n",
    "    test,test['corp'], test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_corp = {idx:list(nouns.keys())[idx] for idx in range(len(list(nouns.keys())))}\n",
    "corp_to_label = {val:idx for idx, val in label_to_corp.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13678"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_length = [len(txt) for txt in df['plain'].values]\n",
    "max(news_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration nlpHakdang___beneficiary-f7051ac6fd8f9af6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/nlpHakdang___beneficiary to /opt/ml/.cache/huggingface/datasets/csv/nlpHakdang___beneficiary-f7051ac6fd8f9af6/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb508a2455a4bd7af09534fa9477863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f78826fd2ed4762a580de1e4ab35432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899ab33f83f04fa1a5482b8631463f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /opt/ml/.cache/huggingface/datasets/csv/nlpHakdang___beneficiary-f7051ac6fd8f9af6/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24da068a25044aad9fe2754201cb9d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "dartdataset = datasets.load_dataset('nlpHakdang/beneficiary',  data_files = \"dart_v3_01.csv\", use_auth_token='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')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_only_kr(s): \n",
    "        hangul = re.compile('[^ ㄱ-ㅣ가-힣+]')\n",
    "        result = hangul.sub('', s)\n",
    "        return ' '.join(result.split())\n",
    "\n",
    "def preprocessing(s): \n",
    "        hangul = re.compile('[^ a-zA-Z0-9ㄱ-ㅣ가-힣+]')\n",
    "        result = hangul.sub('', s)\n",
    "        return ' '.join(result.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = [preprocessing(txt) for txt in dartdataset['train']['사업의 개요']]\n",
    "dartdata = [dartdataset['train']['기업 이름'],preprocess]\n",
    "dartdf = pd.DataFrame (dartdata).transpose()\n",
    "dartdf.columns = ['corp', 'txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stride Code\n",
    "#### DART\n",
    "- 데이터의 형태 colum = ['corp', 'txt']\n",
    "    - corp : 기업이름, txt : 사업의 개요\n",
    "- corp_to_label : 회사이름을 정수로 바꾸는 딕셔너리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dart_split(df : DataFrame) -> pd.DataFrame : \n",
    "    data_list2 = []\n",
    "    for idx in tqdm(range(len(df))):\n",
    "        stride = []\n",
    "        txt = df.iloc[idx]['txt']\n",
    "        if len(txt) < 512:\n",
    "            if df.iloc[idx]['corp'] not in corp_to_label:\n",
    "                continue\n",
    "            data_list2.append([corp_to_label[df.iloc[idx]['corp']],df.iloc[idx]['txt']])\n",
    "        else:\n",
    "            for pointer in range(len(txt)//300):\n",
    "                if pointer == len(txt)//300-1:\n",
    "                    split_txt = txt[-400:]\n",
    "                if pointer != 0:\n",
    "                    split_txt = txt[(pointer*300)-100:((pointer+1)*300)+100]\n",
    "                if pointer == 0:\n",
    "                    split_txt = txt[:400]\n",
    "                if df.iloc[idx]['corp'] not in corp_to_label:\n",
    "                    continue\n",
    "                data_list2.append([corp_to_label[df.iloc[idx]['corp']],df.iloc[idx]['txt']])\n",
    "    return pd.DataFrame(data_list2,columns=['corp', 'txt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### News\n",
    "- 데이터의 형태 colum = ['corp', 'plain', 'maked']\n",
    "    - corp : 기업이름, plain : 원본텍스트, masked:마스크된 텍스트\n",
    "- corp_to_label : 회사이름을 정수로 바꾸는 딕셔너리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_split(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    data_list2 = []\n",
    "    for idx in tqdm(range(len(df))):\n",
    "        stride = []\n",
    "        txt = df.iloc[idx]['masked']\n",
    "        if len(txt) < 512:\n",
    "            data_list2.append([corp_to_label[df.iloc[idx]['corp']],df.iloc[idx]['plain'],df.iloc[idx]['masked']])\n",
    "        else:\n",
    "            for pointer in range(len(txt)//300):\n",
    "                if pointer == len(txt)//300-1:\n",
    "                    split_txt = txt[-400:]\n",
    "                if pointer != 0:\n",
    "                    split_txt = txt[(pointer*300)-100:((pointer+1)*300)+100]\n",
    "                if pointer == 0:\n",
    "                    split_txt = txt[:400]\n",
    "                data_list2.append([corp_to_label[df.iloc[idx]['corp']],df.iloc[idx]['plain'],split_txt])\n",
    "    return pd.DataFrame(data_list2,columns=['corp','plain','masked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52077/52077 [00:26<00:00, 1962.35it/s]\n",
      "100%|██████████| 11159/11159 [00:07<00:00, 1459.20it/s]\n",
      "100%|██████████| 11160/11160 [00:05<00:00, 1966.93it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = bert_split(train)\n",
    "valid_df = bert_split(valid)\n",
    "test_df = bert_split(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2410/2410 [00:04<00:00, 519.67it/s]\n"
     ]
    }
   ],
   "source": [
    "split_dart_df = dart_split(dartdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52077, 11160, 152704, 32702, 2410, 20643)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test), len(train_df), len(test_df), len(dartdf), len(split_dart_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'서울시가 과열된 수주전으로 몸살을 앓고 있는 서울 용산구 한남3구역 재개발 정비사업의 시공사 입찰선정에 대한 특별점검을 진행한다3일 업계에 따르면 서울시는 국토교통부 한국감정원과 합동점검반을 꾸려 4일부터 15일까지 회계처리 정보공개 등 일반적 사항은 물론 최근 과열 기미를 보이는 수주경쟁에 대한 법 위반사항을 점검한다시공사가 입찰제안서에 명시한 설계 등 시공과 관련된 내용이 모두 점검대상에 포함됐다합동점검반은 서울시와 국토부 자치구의 정비사업 담당 공무원과 감정평가사 변호사 회계사 건설 분야별 전문가 등 14명이 참여할 예정이다점검과정에서 불법행위가 적발될 때에는 행정처분 등의 조치를 진행한다지난달 18일 진행한 입찰에는 현대건설 대림산업 GS건설 등 3개사가 참여했다현대건설은 현대백화점 그룹과 손잡고 단'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[0:3]['masked'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'해 진행되는 이번 프로모션은 세상에서 가장 편안한 SUV를 목표로 개발된 시트로엥 뉴 C5 에어크로스 SUV를 한 층 더 완벽하게 경험할 기회를 제공하기 위해 기획됐다시트로엥의 플래그십 SUV 뉴 C5 에어크로스 SUV는 오는 29일부터 4월 7일까지 킨텍스에서 개최되는 2019 서울모터쇼에서 국내 최초로 공개된다모터쇼 기간 동안 뉴 C5 에어크로스 SUV를 계약하는 고객 중 3명에겐 추첨을 통해 레이노 팬텀 S9 풀 시공권이 증정된다세계 최초의 [MASK] 카본 세라믹 기술로 탄생한 레이노 팬텀 틴팅 필름은 카본과 세라믹의 장점만을 융합하여 선명한 시인성과 우수한 변색 방지 내구성으로 사랑받고 있다특히 레이노 팬텀 S9은 적외선을 90% 이상 차단하여 뛰어난 열 차단 성능을 제공하는 프리미엄 제품으로 시트로엥 뉴 C5 에어크로스 SUV와 함께 편안하고 쾌적한 드라이빙 환경을 선사할 것으로 기대된다이 외에도 2019 서울모터쇼 기간 동안 시트로엥 부스에서 진행하는 다양한 이벤트에 참'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[0:3]['masked'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'을 융합하여 선명한 시인성과 우수한 변색 방지 내구성으로 사랑받고 있다특히 레이노 팬텀 S9은 적외선을 90% 이상 차단하여 뛰어난 열 차단 성능을 제공하는 프리미엄 제품으로 시트로엥 뉴 C5 에어크로스 SUV와 함께 편안하고 쾌적한 드라이빙 환경을 선사할 것으로 기대된다이 외에도 2019 서울모터쇼 기간 동안 시트로엥 부스에서 진행하는 다양한 이벤트에 참여하면 차량의 도장면을 보호하고 뛰어난 광택 성능을 제공하는 레이노 블라스크 세라믹 코트 또한 선물 받을 수 있다레이노 코리아의 신현일 지사장은 윈도우 필름 업계에서 새로운 기준을 제시하는 레이노 팬텀과 세상에서 가장 편안한 SUV를 표방하는 뉴 C5 에어크로스 SUV가 만나 소비자의 니즈를 충족하는 시너지를 창출했다며 앞으로도 시트로엥과의 지속적인 콜라보를 통해 고객들에게 만족을 줄 수 있도록 노력해 나가겠다고 밝혔다손균근 기자 kr'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[0:3]['masked'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corp</th>\n",
       "      <th>plain</th>\n",
       "      <th>masked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>922</td>\n",
       "      <td>서울시가 과열된 수주전으로 몸살을 앓고 있는 서울 용산구 한남3구역 재개발 정비사업...</td>\n",
       "      <td>서울시가 과열된 수주전으로 몸살을 앓고 있는 서울 용산구 한남3구역 재개발 정비사업...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>922</td>\n",
       "      <td>서울시가 과열된 수주전으로 몸살을 앓고 있는 서울 용산구 한남3구역 재개발 정비사업...</td>\n",
       "      <td>시공과 관련된 내용이 모두 점검대상에 포함됐다합동점검반은 서울시와 국토부 자치구의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>343</td>\n",
       "      <td>데일리동방 우리은행이 모회사인 우리금융지주의 주식 상당수를 해외 투자자에게 순조롭게...</td>\n",
       "      <td>데일리[MASK] 우리은행이 모회사인 우리금융지주의 주식 상당수를 해외 투자자에게 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>343</td>\n",
       "      <td>데일리동방 우리은행이 모회사인 우리금융지주의 주식 상당수를 해외 투자자에게 순조롭게...</td>\n",
       "      <td>진다앞서 우리금융은 우리카드를 지난 10일 우리금융 자회사로 편입했다우리금융이 우리...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>229</td>\n",
       "      <td>경북지역 5개 대학 150명 대상 6월까지 두 달간경북지역 5개 대학 150명 대상...</td>\n",
       "      <td>경북지역 5개 대학 150명 대상 6월까지 두 달간경북지역 5개 대학 150명 대상...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32697</th>\n",
       "      <td>1183</td>\n",
       "      <td>건국대 글로컬캠퍼스 뉴미디어아트연구소와 이머시브미디어연구소 은이 주관하고 피터앤더울...</td>\n",
       "      <td>건국대 글로컬캠퍼스 뉴미디어아트연구소와 이머시브미디어연구소 은이 주관하고 피터앤더울...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32698</th>\n",
       "      <td>1183</td>\n",
       "      <td>건국대 글로컬캠퍼스 뉴미디어아트연구소와 이머시브미디어연구소 은이 주관하고 피터앤더울...</td>\n",
       "      <td>아티스트와 최신 기술분야 전문가들이 모인 예술과 기술 융합기반의 창작 그룹이다그동...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32699</th>\n",
       "      <td>1614</td>\n",
       "      <td>金지사 지역 출신 의원 초청 간담회SOC 지원 요청김영록 전남지사는 4일 서울 여의...</td>\n",
       "      <td>金지사 지역 출신 의원 초청 간담회SOC 지원 요청김영록 전남지사는 4일 서울 여의...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32700</th>\n",
       "      <td>1614</td>\n",
       "      <td>金지사 지역 출신 의원 초청 간담회SOC 지원 요청김영록 전남지사는 4일 서울 여의...</td>\n",
       "      <td>여의도에서 국회의원 초청 간담회를 열어 정책 현안과 2020년 정부예산안에 미반영...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32701</th>\n",
       "      <td>1614</td>\n",
       "      <td>金지사 지역 출신 의원 초청 간담회SOC 지원 요청김영록 전남지사는 4일 서울 여의...</td>\n",
       "      <td>등에 대한 국회 차원의 협조와 지원을 요청했다또한 청정 전남 블루 이코노미의 본격...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32702 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       corp                                              plain  \\\n",
       "0       922  서울시가 과열된 수주전으로 몸살을 앓고 있는 서울 용산구 한남3구역 재개발 정비사업...   \n",
       "1       922  서울시가 과열된 수주전으로 몸살을 앓고 있는 서울 용산구 한남3구역 재개발 정비사업...   \n",
       "2       343  데일리동방 우리은행이 모회사인 우리금융지주의 주식 상당수를 해외 투자자에게 순조롭게...   \n",
       "3       343  데일리동방 우리은행이 모회사인 우리금융지주의 주식 상당수를 해외 투자자에게 순조롭게...   \n",
       "4       229  경북지역 5개 대학 150명 대상 6월까지 두 달간경북지역 5개 대학 150명 대상...   \n",
       "...     ...                                                ...   \n",
       "32697  1183  건국대 글로컬캠퍼스 뉴미디어아트연구소와 이머시브미디어연구소 은이 주관하고 피터앤더울...   \n",
       "32698  1183  건국대 글로컬캠퍼스 뉴미디어아트연구소와 이머시브미디어연구소 은이 주관하고 피터앤더울...   \n",
       "32699  1614  金지사 지역 출신 의원 초청 간담회SOC 지원 요청김영록 전남지사는 4일 서울 여의...   \n",
       "32700  1614  金지사 지역 출신 의원 초청 간담회SOC 지원 요청김영록 전남지사는 4일 서울 여의...   \n",
       "32701  1614  金지사 지역 출신 의원 초청 간담회SOC 지원 요청김영록 전남지사는 4일 서울 여의...   \n",
       "\n",
       "                                                  masked  \n",
       "0      서울시가 과열된 수주전으로 몸살을 앓고 있는 서울 용산구 한남3구역 재개발 정비사업...  \n",
       "1      시공과 관련된 내용이 모두 점검대상에 포함됐다합동점검반은 서울시와 국토부 자치구의 ...  \n",
       "2      데일리[MASK] 우리은행이 모회사인 우리금융지주의 주식 상당수를 해외 투자자에게 ...  \n",
       "3      진다앞서 우리금융은 우리카드를 지난 10일 우리금융 자회사로 편입했다우리금융이 우리...  \n",
       "4      경북지역 5개 대학 150명 대상 6월까지 두 달간경북지역 5개 대학 150명 대상...  \n",
       "...                                                  ...  \n",
       "32697  건국대 글로컬캠퍼스 뉴미디어아트연구소와 이머시브미디어연구소 은이 주관하고 피터앤더울...  \n",
       "32698   아티스트와 최신 기술분야 전문가들이 모인 예술과 기술 융합기반의 창작 그룹이다그동...  \n",
       "32699  金지사 지역 출신 의원 초청 간담회SOC 지원 요청김영록 전남지사는 4일 서울 여의...  \n",
       "32700   여의도에서 국회의원 초청 간담회를 열어 정책 현안과 2020년 정부예산안에 미반영...  \n",
       "32701   등에 대한 국회 차원의 협조와 지원을 요청했다또한 청정 전남 블루 이코노미의 본격...  \n",
       "\n",
       "[32702 rows x 3 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dart = split_dart_df.rename_axis('id').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_corp = {}\n",
    "for idx in range(len(split_dart)):\n",
    "    id_to_corp[split_dart.iloc[idx]['id']] = split_dart.iloc[idx]['corp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BertModel, BertPreTrainedModel\n",
    ")\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corp</th>\n",
       "      <th>plain</th>\n",
       "      <th>masked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>354</td>\n",
       "      <td>구본영 시장 당선무효형 확정공약현안사업 이행 차질 우려 수장 공백 기강 해이 가능성...</td>\n",
       "      <td>구본영 시장 당선무효형 확정공약현안사업 이행 차질 우려 수장 공백 기강 해이 가능성...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>354</td>\n",
       "      <td>구본영 시장 당선무효형 확정공약현안사업 이행 차질 우려 수장 공백 기강 해이 가능성...</td>\n",
       "      <td>무원들은 설마 했는데 올 것이 왔다는 분위기다일부 간부급 직원들은 예상했던 일이라면...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>354</td>\n",
       "      <td>구본영 시장 당선무효형 확정공약현안사업 이행 차질 우려 수장 공백 기강 해이 가능성...</td>\n",
       "      <td>설 사업 관련 12개 시군 협의체 회장을 구 시장이 맡아왔다는 점에서 추진 동력을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1302</td>\n",
       "      <td>오는 78일 후보 등록 15일 선거 실시 최종 선출자천 타천 23명 거론 중 이사와...</td>\n",
       "      <td>오는 78일 후보 등록 15일 선거 실시 최종 선출자천 타천 23명 거론 중 이사와...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1302</td>\n",
       "      <td>오는 78일 후보 등록 15일 선거 실시 최종 선출자천 타천 23명 거론 중 이사와...</td>\n",
       "      <td>거일 공고문을 지난달 30일 [MASK]문화원 홈페이지 및 게시판에 게시했다[MAS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185434</th>\n",
       "      <td>9</td>\n",
       "      <td>신창균 재화성시문화재단은 2019 찾아가는 공연장을 위해 시민들로부터 신청을 받는다...</td>\n",
       "      <td>신창균 재화성시문화재단은 2019 찾아가는 공연장을 위해 시민들로부터 신청을 받는다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185435</th>\n",
       "      <td>9</td>\n",
       "      <td>신창균 재화성시문화재단은 2019 찾아가는 공연장을 위해 시민들로부터 신청을 받는다...</td>\n",
       "      <td>을 신청할 수 있다고 밝혔다재단은 공연 운영이 가능한 실내 공간을 확보한 시민에 한...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185436</th>\n",
       "      <td>468</td>\n",
       "      <td>서울경제 아이템 스페셜 티저 포스터 2종이 전격 공개됐다주연 배우가 아닌 의미를 알...</td>\n",
       "      <td>서울경제 아이템 스페셜 티저 포스터 2종이 전격 공개됐다주연 배우가 아닌 의미를 알...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185437</th>\n",
       "      <td>468</td>\n",
       "      <td>서울경제 아이템 스페셜 티저 포스터 2종이 전격 공개됐다주연 배우가 아닌 의미를 알...</td>\n",
       "      <td>아이템을 향한 간절함이 담긴 인물의 이야기가 펼쳐질 것임을 예고하고 있다먼저 아이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185438</th>\n",
       "      <td>468</td>\n",
       "      <td>서울경제 아이템 스페셜 티저 포스터 2종이 전격 공개됐다주연 배우가 아닌 의미를 알...</td>\n",
       "      <td>버전의 심볼이 그려져 있다는 것 역시 의미심장하다이 아이템을 나타내는 심볼과 드림월...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185439 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        corp                                              plain  \\\n",
       "0        354  구본영 시장 당선무효형 확정공약현안사업 이행 차질 우려 수장 공백 기강 해이 가능성...   \n",
       "1        354  구본영 시장 당선무효형 확정공약현안사업 이행 차질 우려 수장 공백 기강 해이 가능성...   \n",
       "2        354  구본영 시장 당선무효형 확정공약현안사업 이행 차질 우려 수장 공백 기강 해이 가능성...   \n",
       "3       1302  오는 78일 후보 등록 15일 선거 실시 최종 선출자천 타천 23명 거론 중 이사와...   \n",
       "4       1302  오는 78일 후보 등록 15일 선거 실시 최종 선출자천 타천 23명 거론 중 이사와...   \n",
       "...      ...                                                ...   \n",
       "185434     9  신창균 재화성시문화재단은 2019 찾아가는 공연장을 위해 시민들로부터 신청을 받는다...   \n",
       "185435     9  신창균 재화성시문화재단은 2019 찾아가는 공연장을 위해 시민들로부터 신청을 받는다...   \n",
       "185436   468  서울경제 아이템 스페셜 티저 포스터 2종이 전격 공개됐다주연 배우가 아닌 의미를 알...   \n",
       "185437   468  서울경제 아이템 스페셜 티저 포스터 2종이 전격 공개됐다주연 배우가 아닌 의미를 알...   \n",
       "185438   468  서울경제 아이템 스페셜 티저 포스터 2종이 전격 공개됐다주연 배우가 아닌 의미를 알...   \n",
       "\n",
       "                                                   masked  \n",
       "0       구본영 시장 당선무효형 확정공약현안사업 이행 차질 우려 수장 공백 기강 해이 가능성...  \n",
       "1       무원들은 설마 했는데 올 것이 왔다는 분위기다일부 간부급 직원들은 예상했던 일이라면...  \n",
       "2       설 사업 관련 12개 시군 협의체 회장을 구 시장이 맡아왔다는 점에서 추진 동력을 ...  \n",
       "3       오는 78일 후보 등록 15일 선거 실시 최종 선출자천 타천 23명 거론 중 이사와...  \n",
       "4       거일 공고문을 지난달 30일 [MASK]문화원 홈페이지 및 게시판에 게시했다[MAS...  \n",
       "...                                                   ...  \n",
       "185434  신창균 재화성시문화재단은 2019 찾아가는 공연장을 위해 시민들로부터 신청을 받는다...  \n",
       "185435  을 신청할 수 있다고 밝혔다재단은 공연 운영이 가능한 실내 공간을 확보한 시민에 한...  \n",
       "185436  서울경제 아이템 스페셜 티저 포스터 2종이 전격 공개됐다주연 배우가 아닌 의미를 알...  \n",
       "185437   아이템을 향한 간절함이 담긴 인물의 이야기가 펼쳐질 것임을 예고하고 있다먼저 아이...  \n",
       "185438  버전의 심볼이 그려져 있다는 것 역시 의미심장하다이 아이템을 나타내는 심볼과 드림월...  \n",
       "\n",
       "[185439 rows x 3 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "dart_tok = tokenizer( list(split_dart_df['txt']) ,padding = \"max_length\", return_tensors = \"pt\", truncation = True) \n",
    "train_tok = tokenizer( list(train_df['masked']) ,padding = \"max_length\", return_tensors = \"pt\", truncation = True)\n",
    "valid_tok = tokenizer( list(valid_df['masked']) ,padding = \"max_length\", return_tensors = \"pt\", truncation = True)\n",
    "test_tok = tokenizer(list(test_df['masked']),padding = \"max_length\", return_tensors = \"pt\", truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corp_code = torch.tensor(train_df['corp'])\n",
    "valid_corp_code = torch.tensor(valid_df['corp'])\n",
    "test_corp_code = torch.tensor(test_df['corp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20643, 512]), torch.Size([152704, 512]), torch.Size([152704]))"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dart_tok['input_ids'].shape, train_tok['input_ids'].shape, train_corp_code.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dart_tok.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TensorDataset(\n",
    "    train_tok['input_ids'], train_tok['token_type_ids'], train_tok['attention_mask'], \\\n",
    "    train_corp_code)\n",
    "\n",
    "valid_set = TensorDataset(\n",
    "    valid_tok['input_ids'], valid_tok['token_type_ids'], valid_tok['attention_mask'], \\\n",
    "    valid_corp_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fcd96e8f410>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "dataloader = DataLoader(train_set, batch_size=BATCH_SIZE)\n",
    "\n",
    "val_dataloader = DataLoader(valid_set, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(BertEncoder, self).__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self,\n",
    "            input_ids, \n",
    "            attention_mask=None,\n",
    "            token_type_ids=None\n",
    "        ): \n",
    "  \n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        pooled_output = outputs[1]\n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "news_encoder = BertEncoder.from_pretrained(\"klue/bert-base\").to(device)\n",
    "dart_encoder = BertEncoder.from_pretrained(\"klue/bert-base\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "news_optimizer = optim.SGD(news_encoder.parameters(), lr=0.01, momentum=0.9)\n",
    "dart_optimizer = optim.SGD(dart_encoder.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "epochs = 3\n",
    "for e in range( epochs ):\n",
    "    e_loss = 0\n",
    "    for batch in tq.tqdm( dataloader ):\n",
    "        news_data = {\n",
    "            'input_ids' : batch[0].to(device).to(torch.int64), # ( B, seq_len )\n",
    "            'token_type_ids' : batch[1].to(device).to(torch.int64),\n",
    "            'attention_mask' : batch[2].to(device).to(torch.int64),\n",
    "        }\n",
    "        \n",
    "        dart_data = {\n",
    "            'input_ids' : batch[3].to(device).to(torch.int64), # ( B, seq_len )\n",
    "            'token_type_ids' : batch[4].to(device).to(torch.int64),\n",
    "            'attention_mask' : batch[5].to(device).to(torch.int64),\n",
    "        }\n",
    "\n",
    "        corp_table = batch[6]\n",
    "\n",
    "\n",
    "        corp_code = corp_table.tolist()\n",
    "        dic = {}\n",
    "\n",
    "\n",
    "        batch_size = batch[0].shape[0]\n",
    "        del batch\n",
    "        \n",
    "        news_encoder.train()\n",
    "        news_encoder.zero_grad()\n",
    "        news_emb = news_encoder(**news_data) # (B, hidden_dim)\n",
    "        dart_encoder.train()\n",
    "        dart_encoder.zero_grad()\n",
    "        dart_emb = dart_encoder(**dart_data) # (B, hidden_dim)\n",
    "        sim_score = torch.matmul( news_emb, dart_emb.T ) # (B , B)\n",
    "        \n",
    "        target = torch.arange(start=0, end = batch_size).to(device).to(torch.int64)\n",
    "    \n",
    "        CE_loss = CrossEntropyLoss()\n",
    "        loss = CE_loss(sim_score, target)\n",
    "        e_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        dart_optimizer.step()\n",
    "        news_optimizer.step()\n",
    "\n",
    "        del dart_emb\n",
    "        del news_emb\n",
    "        torch.cuda.empty_cache()\n",
    "    print(e_loss / len(dataloader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightweight",
   "language": "python",
   "name": "lightweight"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
