{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration nlpHakdang___aihub-news30k-1ea472361ab2489f\n",
      "Reusing dataset csv (/opt/ml/.cache/huggingface/datasets/csv/nlpHakdang___aihub-news30k-1ea472361ab2489f/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9594d467bb2438fb9e26ed278e6d164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "news_dataset = load_dataset('nlpHakdang/aihub-news30k',  data_files={\"train\":\"news_train_1_1.csv\", \"valid\":\"news_valid_1_1.csv\"}, use_auth_token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'category', 'media_sub_type', 'media_name', 'char_count', 'publish_date', 'title', 'original', 'article', 'extractive', 'abstract'],\n",
       "        num_rows: 271093\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['id', 'category', 'media_sub_type', 'media_name', 'char_count', 'publish_date', 'title', 'original', 'article', 'extractive', 'abstract'],\n",
       "        num_rows: 30122\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting kobart\n",
      "  Cloning https://github.com/SKT-AI/KoBART to /tmp/pip-install-uswpbj7g/kobart_80b8f982e04944aca699e9bfb94dd51d\n",
      "  Running command git clone --filter=blob:none -q https://github.com/SKT-AI/KoBART /tmp/pip-install-uswpbj7g/kobart_80b8f982e04944aca699e9bfb94dd51d\n",
      "  Resolved https://github.com/SKT-AI/KoBART to commit 1811d3779cf394872f32073d01c1201c8525bc00\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: boto3 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from kobart) (1.20.26)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from kobart) (1.1.5)\n",
      "Requirement already satisfied: pytorch-lightning==1.2.1 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from kobart) (1.2.1)\n",
      "Collecting torch==1.7.1\n",
      "  Using cached torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
      "Collecting transformers==4.3.3\n",
      "  Using cached transformers-4.3.3-py3-none-any.whl (1.9 MB)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from pytorch-lightning==1.2.1->kobart) (4.62.3)\n",
      "Requirement already satisfied: future>=0.17.1 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from pytorch-lightning==1.2.1->kobart) (0.18.2)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from pytorch-lightning==1.2.1->kobart) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from pytorch-lightning==1.2.1->kobart) (1.21.4)\n",
      "Requirement already satisfied: PyYAML!=5.4.*,>=5.1 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from pytorch-lightning==1.2.1->kobart) (6.0)\n",
      "Requirement already satisfied: fsspec[http]>=0.8.1 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from pytorch-lightning==1.2.1->kobart) (2021.11.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from torch==1.7.1->kobart) (3.10.0.2)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from transformers==4.3.3->kobart) (0.0.46)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from transformers==4.3.3->kobart) (2.26.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from transformers==4.3.3->kobart) (4.8.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from transformers==4.3.3->kobart) (2021.11.10)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from transformers==4.3.3->kobart) (0.10.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from transformers==4.3.3->kobart) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from transformers==4.3.3->kobart) (21.2)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from boto3->kobart) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.26 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from boto3->kobart) (1.23.26)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from boto3->kobart) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from pandas->kobart) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from pandas->kobart) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.26->boto3->kobart) (1.26.7)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart) (3.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->kobart) (1.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (0.4.6)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (3.19.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (1.0.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (1.43.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (58.0.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (0.37.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (2.3.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (1.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from requests->transformers==4.3.3->kobart) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from requests->transformers==4.3.3->kobart) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from requests->transformers==4.3.3->kobart) (2021.10.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from importlib-metadata->transformers==4.3.3->kobart) (3.6.0)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from packaging->transformers==4.3.3->kobart) (2.4.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from sacremoses->transformers==4.3.3->kobart) (1.1.0)\n",
      "Requirement already satisfied: click in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from sacremoses->transformers==4.3.3->kobart) (8.0.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (1.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart) (4.0.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart) (0.13.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart) (1.7.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart) (21.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart) (5.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch-lightning==1.2.1->kobart) (1.2.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/lightweight/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.1->kobart) (3.1.1)\n",
      "Building wheels for collected packages: kobart\n",
      "  Building wheel for kobart (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kobart: filename=kobart-0.5.1-py3-none-any.whl size=9563 sha256=40420e875e72d48e7a837e153f97fba8646c8e3d33a4aac3d164d8dc3ceee74f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-tri20swv/wheels/6e/55/c4/bd4fede223bc304089ac8da2a2099a69db3fcd4b0e853383f5\n",
      "Successfully built kobart\n",
      "Installing collected packages: torch, transformers, kobart\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.10.1\n",
      "    Uninstalling torch-1.10.1:\n",
      "      Successfully uninstalled torch-1.10.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.14.1\n",
      "    Uninstalling transformers-4.14.1:\n",
      "      Successfully uninstalled transformers-4.14.1\n",
      "  Attempting uninstall: kobart\n",
      "    Found existing installation: kobart 0.4\n",
      "    Uninstalling kobart-0.4:\n",
      "      Successfully uninstalled kobart-0.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers-domain-adaptation 0.3.1 requires datasets<1.3,>=1.2, but you have datasets 1.16.1 which is incompatible.\n",
      "transformers-domain-adaptation 0.3.1 requires tokenizers<0.10,>=0.9, but you have tokenizers 0.10.3 which is incompatible.\n",
      "torchvision 0.7.0 requires torch==1.6.0, but you have torch 1.7.1 which is incompatible.\n",
      "sentence-transformers 2.1.0 requires transformers<5.0.0,>=4.6.0, but you have transformers 4.3.3 which is incompatible.\n",
      "pororo 0.4.2 requires torch==1.6.0, but you have torch 1.7.1 which is incompatible.\n",
      "kobert 0.2.1 requires transformers>=4.8.1, but you have transformers 4.3.3 which is incompatible.\u001b[0m\n",
      "Successfully installed kobart-0.5.1 torch-1.7.1 transformers-4.3.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/SKT-AI/KoBART#egg=kobart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['▁안녕하', '세요.', '▁한국어', '▁B', 'A', 'R', 'T', '▁입', '니다.', '🤣', ':)', 'l^o']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kobart import get_kobart_tokenizer\n",
    "kobart_tokenizer = get_kobart_tokenizer()\n",
    "kobart_tokenizer.tokenize(\"안녕하세요. 한국어 BART 입니다.🤣:)l^o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartModel\n",
    "from kobart import get_pytorch_kobart_model, get_kobart_tokenizer\n",
    "\n",
    "kobart_tokenizer = get_kobart_tokenizer()\n",
    "model = BartModel.from_pretrained(get_pytorch_kobart_model())\n",
    "\n",
    "inputs = kobart_tokenizer(['안녕하세요.'], return_tensors='pt')\n",
    "outputs = model(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "from transformers.models.bart import BartForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "def load_model():\n",
    "    model = BartForConditionalGeneration.from_pretrained(get_pytorch_kobart_model())\n",
    "    # tokenizer = get_kobart_tokenizer()\n",
    "    return model\n",
    "\n",
    "model = load_model()\n",
    "tokenizer = get_kobart_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Integer division of tensors using div or / is no longer supported, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16732/3045542214.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/lightweight/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTypeVar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFuncType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_DecoratorContextManager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m\"\"\"Allow a context manager to be used as a decorator\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/lightweight/lib/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogitsProcessor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mmodify\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0mscores\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m                 \u001b[0mhead\u001b[0m \u001b[0mapplied\u001b[0m \u001b[0mat\u001b[0m \u001b[0meach\u001b[0m \u001b[0mgeneration\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m             \u001b[0mmax_length\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mint\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0moptional\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1081\u001b[0m                 \u001b[0mThe\u001b[0m \u001b[0mmaximum\u001b[0m \u001b[0mlength\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msequence\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m             \u001b[0mpad_token_id\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mint\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0moptional\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/lightweight/lib/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m         \u001b[0mbatch_beam_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1855\u001b[0;31m         \u001b[0mbeam_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m         \u001b[0mbeam_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Integer division of tensors using div or / is no longer supported, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead."
     ]
    }
   ],
   "source": [
    "text = \"애플이 내년 하반기 출시할 아이폰14(가칭)에 펀치홀(카메라 구멍) 디스플레이를 적용할 것이라는 전망이 나오면서 아이폰 공급망에 포함돼 있는 삼성디스플레이, LG디스플레이, 중국 BOE의 표정이 엇갈린다. 이미 갤럭시 시리즈에 펀치홀 유기발광다이오드(OLED) 패널을 대량 공급한 이력이 있는 삼성디스플레이는 여유로운 분위기가 감지된다. LG디스플레이는 공급 경험은 없지만 펀치홀 디스플레이의 기술 난이도가 높지 않은 것으로 판단한다. 반면 공급 경험이 있지만 디스플레이 기술력이 상대적으로 떨어지는 BOE는 일단 애플이 요구하는 기술 수준을 따라가는 데 주력할 것으로 보인다.17일 폰아레나 등 해외 정보기술(IT) 전문매체 등에 따르면 애플은 내년 출시할 아이폰14 시리즈 고급 모델인 프로의 전면 디자인에서 ‘노치’를 빼고 펀치홀을 적용한다. 노치는 디스플레이 상단의 일정 부분을 카메라 모듈과 센서 등에 할애하는 디자인으로, 생김새가 한자 ‘오목할 요(凹)’자와 유사하다. 이 때문에 ‘M자 탈모’라고도 불린다. 애플은 페이스ID라는 안면인식 보안기술을 위해 노치 디자인을 지난 2018년 출시한 아이폰X(텐)부터 최근 내놓은 아이폰13까지 유지하고 있다.\"\n",
    "#text = \"삼성바이오로직스가 최근 주가 급등에 힘입어 네이버를 밀어내고 코스피 시가총액 3위에 올랐다. 17일 오전 9시51분 기준 삼성바이오로직스는 96만2,000원에 거래되고 있다. 맥쿼리, CS증권 등 외국계 창구를 통한 순매수세가 유입되고 있다. 삼성바이오로직스는 전일에도 6% 가까이 상승 마감했으며 지난 14일부터 4거래일 연속 상승세를 나타내고 있다. 시가총액은 현재가 기준 63조7,831억 원으로 네이버를 앞질렀다. 삼성바이오로직스와 네이버의 시총 격차는 현재 3,774억 원 수준이다.\"\n",
    "if text:\n",
    "    text = text.replace('\\n', '')\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    input_ids = input_ids.unsqueeze(0)\n",
    "    output = model.generate(input_ids, eos_token_id=1, min_length=32, max_length=512, num_beams=5)\n",
    "    output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화 시스템 평가 , 번역의 정답."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /opt/ml/final-project-level3-nlp-06/summarize/.cache/kobert_v1.zip\n",
      "using cached model. /opt/ml/final-project-level3-nlp-06/summarize/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
    "input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
    "token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])\n",
    "model, vocab  = get_pytorch_kobert_model()\n",
    "sequence_output, pooled_output = model(input_ids, input_mask, token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocab(size=8002, unk=\"[UNK]\", reserved=\"['[CLS]', '[SEP]', '[MASK]', '[PAD]']\")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2461,  0.2428,  0.2590,  ..., -0.4861, -0.0731,  0.0756],\n",
       "        [-0.2478,  0.2420,  0.2552,  ..., -0.4877, -0.0727,  0.0754],\n",
       "        [-0.2472,  0.2420,  0.2561,  ..., -0.4874, -0.0733,  0.0765]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting kobert_tokenizer\n",
      "  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-mkn6k4ek/kobert-tokenizer_e5ab57838c9c4671bf68d5cb457322d2\n",
      "  Running command git clone --filter=blob:none -q https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-mkn6k4ek/kobert-tokenizer_e5ab57838c9c4671bf68d5cb457322d2\n",
      "  Resolved https://github.com/SKTBrain/KoBERT.git to commit d0c0829be97b3a363a8035d4131e8be4988e129d\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b04e1321ca44389ebbaea2d3807aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/363k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3c949341b04e6f83d50473edbf6495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/244 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6cc47980d14516b3e9c5a5c0cd635d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/432 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 4958, 6855, 2046, 7088, 1050, 7843, 54, 3]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "tokenizer.encode(\"한국어 모델을 공유합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/lightweight/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'new_ones'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16732/371557594.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"한국어 모델을 공유합니다.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_encode_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/lightweight/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# See https://mypy.readthedocs.io/en/latest/generics.html#declaring-decorators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mFuncType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTypeVar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFuncType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/lightweight/lib/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inputs_embeds\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             model_kwargs[\"attention_mask\"] = self._prepare_attention_mask_for_generation(\n\u001b[0;32m--> 905\u001b[0;31m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_token_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos_token_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m             )\n\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/lightweight/lib/python3.7/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36m_prepare_attention_mask_for_generation\u001b[0;34m(self, input_ids, pad_token_id, eos_token_id, inputs_embeds)\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_ones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     def _prepare_encoder_decoder_kwargs_for_generation(\n",
      "\u001b[0;32m/opt/conda/envs/lightweight/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel\n",
    "model = BertModel.from_pretrained('skt/kobert-base-v1')\n",
    "text = \"한국어 모델을 공유합니다.\"\n",
    "inputs = tokenizer.batch_encode_plus([text])\n",
    "output = model.generate(inputs, eos_token_id=1, max_length=64, num_beams=5)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(input_ids, eos_token_id=1, max_length=64, num_beams=5)\n",
    "output = tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE = \"삼성바이오로직스가 최근 주가 급등에 힘입어 네이버를 밀어내고 코스피 시가총액 3위에 올랐다. 17일 오전 9시51분 기준 삼성바이오로직스는 96만2,000원에 거래되고 있다. 맥쿼리, CS증권 등 외국계 창구를 통한 순매수세가 유입되고 있다. 삼성바이오로직스는 전일에도 6% 가까이 상승 마감했으며 지난 14일부터 4거래일 연속 상승세를 나타내고 있다. 시가총액은 현재가 기준 63조7,831억 원으로 네이버를 앞질렀다. 삼성바이오로직스와 네이버의 시총 격차는 현재 3,774억 원 수준이다.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, BertConfig\n",
    "\n",
    "config = BertConfig.from_pretrained(\"skt/kobert-base-v1\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"skt/kobert-base-v1\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"skt/kobert-base-v1\")\n",
    "\n",
    "# T5 uses a max_length of 512 so we cut the article to 512 tokens.\n",
    "inputs = tokenizer(\"summarize: \" + ARTICLE, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "outputs = model.generate(\n",
    "    inputs[\"input_ids\"], max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the HuggingFace summarization pipeline\n",
    "summarizer = pipeline(\"summarization\")\n",
    "summarized = summarizer(inputs[\"input_ids\"], min_length=75, max_length=300)\n",
    "\n",
    "# Print summarized text\n",
    "print(summarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e31c68abf1d5dd3f9e2269f23eadf1b199587e56c0618a30760176a65ebfcab4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('lightweight': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
