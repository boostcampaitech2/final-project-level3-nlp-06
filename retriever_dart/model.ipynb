{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f47ec80-e266-41ae-ba64-84b3dcb3fd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration nlpHakdang___aihub-news30k-4ae9b68bff3cf5c2\n",
      "Reusing dataset csv (/opt/ml/.cache/huggingface/datasets/csv/nlpHakdang___aihub-news30k-4ae9b68bff3cf5c2/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194944a04be14479a93fdea6f0a33f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/lightweight/lib/python3.7/site-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/envs/lightweight/lib/python3.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dart_prcs import *\n",
    "\n",
    "news_dataset = datasets.load_dataset('nlpHakdang/aihub-news30k',  data_files={\"train\":\"news_train_1_1.csv\", \"valid\":\"news_valid_1_1.csv\"}, use_auth_token='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')\n",
    "\n",
    "news_train_set = news_dataset['train']\n",
    "news_val_set = news_dataset['valid']\n",
    "\n",
    "\n",
    "\n",
    "def stringfy(tmp):\n",
    "    tmp = eval(tmp) \n",
    "    return \" \".join( tmp )\n",
    "\n",
    "def preprocess(text):\n",
    "    import regex as re\n",
    "    text = remove_repeated_spacing(text)\n",
    "    text = clean_punc(text)\n",
    "    text = remove_useless_breacket(text)\n",
    "    text = remove_email(text)\n",
    "    text = remove_url(text)\n",
    "    text = re.sub(\"\\n\", \"\", text) \n",
    "    text = re.sub(\"\\\"\", \"\", text)\n",
    "    text = re.sub(\"\\'\", \"\", text)\n",
    "    text = re.sub(\"-\", \"\", text)\n",
    "    text = re.sub(\"\\\"\", \"\", text)\n",
    "    text = re.sub(\"\\'\", \"\", text)\n",
    "    text = re.sub(\",\", \"\", text)\n",
    "    text = re.sub(\"\\.\", \"\", text)\n",
    "    text = re.sub(\"(주)\", \"\", text)\n",
    "    text = re.sub(\"\\)\", \" \", text)\n",
    "    text = re.sub(\"\\(\", \" \", text)\n",
    "    \n",
    "    # text = re.sub(\"[(]\", \" (\", text)\n",
    "    # text = re.sub(\"[)]\", \") \", text)\n",
    "    text = re.sub('[■:%/~㈜↓&※·→①②$③○-ㆍ」「■>Ⅱ④;▶●?⑤社⑥⑦□=ㅇ『』外<◆△【】現▲▷美∼用☞@前㎡◇中Ⅲ－無新內％◈}株ㅁ會㎥{ㄱⅠ化高＋ㄴ日有：ㄷ公司全後限，〔〕學↑式月|＆ℓㄹ…業人名《》年^韓部▼本大小海│愛故食形㎏獨山多水東可非思州國家生上℃ㅂ合金發在同⊙軍英物實田開○○○○○作性體度産空分子光重ㅅ島間時利＂面母≪㎖資心別氣仁未京來對成雲淸聖命保的集史靑場法神正第一硏㎞ㅡ★太民如理出入下解得安平＝帝所市石門相方元政先富北木自車南地―｜求ㅎㅎ≫西長銀者規制女江福和ㅌ通主義村當代力㎝善原選色；古河──都能動歌〈〉不定ㅠ吉事理張數朝金㎜記書]'\\\n",
    "                      , \" \", text)\n",
    "    text = remove_repeated_spacing(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def prcs_news_dataset(dataset):\n",
    "    news_df = pd.DataFrame( {'title' : dataset['title'], 'original' : dataset['original'], 'category':dataset['category'],'article' : dataset['article'] } )\n",
    "    eco_df = news_df[ news_df['category'] == \"경제\" ]\n",
    "    eco_df['new_article'] = eco_df['original'].map(stringfy)\n",
    "    eco_df['new_article'] = eco_df['new_article'].map(preprocess)\n",
    "    return eco_df\n",
    "new_tr_df = prcs_news_dataset( news_train_set )\n",
    "new_vl_df = prcs_news_dataset( news_val_set )\n",
    "\n",
    "r = np.random.randint(len(new_tr_df))\n",
    "new_tr_df.iloc[r]['new_article'],new_tr_df.iloc[r]['original']\n",
    "\n",
    "del new_tr_df['original']\n",
    "del new_tr_df['article']\n",
    "del new_vl_df['original']\n",
    "del new_vl_df['article']\n",
    "\n",
    "# new_tr_df.to_csv(\"news_train_ret_v0.csv\")\n",
    "# new_vl_df.to_csv(\"news_valid_ret_v0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf1b6193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration nlpHakdang___beneficiary-f7051ac6fd8f9af6\n",
      "Reusing dataset csv (/opt/ml/.cache/huggingface/datasets/csv/nlpHakdang___beneficiary-f7051ac6fd8f9af6/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341d58f8390f4589b3360b7f386dc625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"nlpHakdang/beneficiary\", data_files = \"dart_v3_01.csv\", use_auth_token= \"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\")\n",
    "dataset\n",
    "dart_df = pd.DataFrame( dataset['train'] )\n",
    "del dart_df['회사의 개요']\n",
    "del dart_df['회사의 연혁']\n",
    "del dart_df['주요 제품 및 서비스']\n",
    "del dart_df['주요계약 및 연구개발활동']\n",
    "\n",
    "# df.to_csv(\"dart_ret_v0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2daad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_df = pd.read_csv(\"news_train_ret_v0.csv\")\n",
    "news_data = list( new_tr_df['new_article'] )\n",
    "\n",
    "# dart_df = pd.read_csv(\"dart_ret_v0.csv\")\n",
    "dart_data = dart_df['사업의 개요'].map(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d25a292-196e-42b2-9109-9388aa1d5123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BertModel, BertPreTrainedModel,\n",
    "    # AdamW, get_linear_schedule_with_warmup,\n",
    "    # TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0da3479-7bc2-4ed1-8ee3-6235903977ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed825220-d43c-4b54-bcb8-1a5f9ff7a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = news_data[:10]\n",
    "news_tok = tokenizer(tmp, padding = \"max_length\", return_tensors = \"pt\", truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3b652a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['당사는 체외진단 기술을 토대로 면역화학진단 바이오센서 분자진단 기술을 기반으로 진단 제품을 개발 제조 판매하는 사업을 영위하고 있습니다  회사의 사업은 작게는 현장진단검사 (Point of Care Test  POCT) 시장에 속해 있고 크게는 체외진단 (InVitro Diagnostics) 시장에 속해 있습니다  당사에서 생산하고 있는 진단시약은 기타의약품으로 분류되어 의약품 제조기준에 규제를 받고 있습니다 ',\n",
       " '체외진단 시장은 인구 고령화 및 감염성 질병의 퇴치 질병 확산 방지를 위한 수요 증가에 따라 꾸준히 성장하고 있습니다  체외진단 시장에서도 현장진단 (Point of Care Testing) 분야는 그 접근성과 편리성 신속성 비용면에서의 장점들로 인해 더욱 목받고 있습니다  최근에는 진단의 정확도 및 편의성을 증대하고 진단 정보를 관리하기위해 BT NT IT 기술 융합을 통한 차세대 체외진단기기가 개발되고 있어 과학 기술 발달은 현장진단시장의 성장을 더욱 촉진하고 있습니다  식품의약품안전평가원의 2019년 신개발 의료기기 전망분석 보고서 에 따르면 체외진단기기 세계시장은 2015년 약 52조 2천억원에서 2025년에는 78조 5천 3백억원으로 연평균 약 4 2  성장률이 예상되고 있으며 현장진단기기 세계시장은 2015년 7조 6천억원에서 2023년 11조 8천 6백억원으로 연평균 5 6 의 높은 시장 성장률을 보일 것으로 전망됩니다  당사의 요 제품은 말라리아 독감 코비드19과 같은 감염성 질병을 진단하는 신속진단시약입니다  말라리아 진단제품은 아프리카에서 로 발병하는 열대열 말라리아 진단 제품 뿐 아니라 여러 종류의 말라리아 진단도 병행할 수 있는 Combo RDT 제품 중남미와 아프리카 지역에서 발견되고 있는 변종 말라리아 진단 제품까지 총 11가지 종류의 제품을 보유하고 있습니다  또한 2020년과 2021년도에 걸쳐 코로나 진단 제품 5종 (신속진단키트인 COVID19IgG IgM COVID19 antigen test EZ Covid19 IgG IgM COVID19 Antigen Hometest 분자진단키트인 COVID19 RTPCR) 에 대하여 미 FDA로부터 긴급사용승인 (Emergency Use Authorization) 을 획득하면서 코로나 진단제품이 요 매출로자리매김하였습니다 ',\n",
       " '당사의 매출은 기본적으로 공공부문과 민간부분으로 이루어지고 있습니다  말라리아의 경우 아프리카 동남아시아 지역에서 많이 발생하고 있으며 해당 국가들은 대부분 경제적 결핍 및 의료시설 미비로 의료 혜택을 받기 어려운 경우가 많습니다  이에 말라리아 진단제품은 일반적으로 WHO UNICEF 등과 같은 국제기구 및 각국 보건복지부 관의 입찰시장을 통하여 각 국가의 병원 보건소 등에 배급되는 형태를 이루고 있습니다  반면 선진시장의 경우 의료기기 전문 유통사를 통하여 판매를 진행하고 있습니다  당사의 제 20기 3분기 누적 매출액은 2831억원이며 전년 동기 연결 매출액은 307억원입니다 ']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dart_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a733b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bee3c75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7f9c32ebe190>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TensorDataset(news_tok['input_ids'],news_tok['token_type_ids'],news_tok['attention_mask']\\\n",
    "    )\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9b0a088e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fd5c05e4150>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=8)\n",
    "dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "63ca2c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(BertEncoder, self).__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.init_weights()\n",
    "      \n",
    "      \n",
    "    def forward(self,\n",
    "            input_ids, \n",
    "            attention_mask=None,\n",
    "            token_type_ids=None\n",
    "        ): \n",
    "  \n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        pooled_output = outputs[1]\n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ee1d13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertEncoder.from_pretrained(\"klue/bert-base\").to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d97dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfce758-4651-4d01-92d4-50374418be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_dataset(self,\n",
    "#     dataset=None,\n",
    "#     tokenizer=None\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Arguments:\n",
    "#         dataset (datasets.Dataset, default=None):\n",
    "#             Huggingface의 Dataset을 받아오면,\n",
    "#             in-batch negative를 추가해서 Dataloader를 만들어주세요.\n",
    "#         num_neg (int, default=2):\n",
    "#             In-batch negative 수행시 사용할 negative sample의 수를 받아옵니다.\n",
    "#         tokenizer (Callable, default=None):\n",
    "#             Tokenize할 함수를 받아옵니다.\n",
    "#             별도로 받아오지 않으면 속성으로 저장된 Tokenizer를 불러올 수 있게 짜주세요.\n",
    "#     Note:\n",
    "#         모든 Arguments는 사실 이 클래스의 속성으로 보관되어 있기 때문에\n",
    "#         별도로 Argument를 직접 받지 않아도 수행할 수 있게 만들어주세요.\n",
    "#     \"\"\"\n",
    "#     if dataset is None:\n",
    "#         dataset = self.dataset\n",
    "#     if tokenizer is None:\n",
    "#         tokenizer = self.tokenizer\n",
    "\n",
    "#     corpus =dataset['context'] # query <-> context 1:1 대응 관계\n",
    "#     q = dataset['question'] # (batch)\n",
    "\n",
    "#     p_seg = tokenizer(corpus, padding = \"max_length\",return_tensors = \"pt\",truncation = True)\n",
    "#     q_seg = tokenizer(q, padding = \"max_length\",\\\n",
    "#                                 return_tensors = \"pt\",\\\n",
    "#                                 truncation = True\n",
    "#                                 )\n",
    "#     dataset = TensorDataset(p_seg['input_ids'], p_seg['attention_mask'],   p_seg['token_type_ids'],  \n",
    "#                             q_seg['input_ids'], q_seg['attention_mask'],   q_seg['token_type_ids'])\n",
    "#     self.dataloader = DataLoader(dataset, batch_size=self.args.per_device_train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3864cb-b4d8-40fc-9acd-c49978e7b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"nlpHakdang/beneficiary\", data_files = \"dart_v0.csv\", use_auth_token= \"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\")\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
